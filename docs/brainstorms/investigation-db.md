# Investigation DB

> ðŸ” Pattern-based reverse lookup for data pipelines

## The Problem

â“ When a file is missing in Gold/Platinum, how do we trace it back?

```mermaid
flowchart LR
    Q[/"âŒ Missing Gold File"/]
    Q --> |"?"| B["ðŸ“¦ Bronze Source"]
    Q --> |"?"| S["âš™ï¸ Service"]
    Q --> |"?"| SRV["ðŸ–¥ï¸ Server"]
```

## Sample Query

![Datasette Sample](../assets/images/invdb-datasette-sample.png)

*Reverse lookup: sf_table â†’ enriched_file â†’ platinum_path â†’ raw_path*

## Core Idea

ðŸ’¡ **Don't track files - track patterns!**

```mermaid
flowchart LR
    subgraph Input
        G["ðŸ“ Gold Pattern"]
    end

    subgraph Lookup
        DB[("ðŸ—„ï¸ Investigation DB")]
    end

    subgraph Output
        B["ðŸ“¦ Bronze Pattern"]
        SVC["âš™ï¸ Service"]
        SRV["ðŸ–¥ï¸ Server"]
    end

    G --> DB
    DB --> B
    DB --> SVC
    DB --> SRV
```

## Key Entities

```mermaid
mindmap
  root((ðŸ—„ï¸ Investigation DB))
    ðŸ–¥ï¸ Infrastructure
      Servers
      Services
      Credentials
    ðŸ“¥ Data Sources
      Vendors
      Datasets
      Raw Landing
    ðŸ§© Patterns
      File Patterns
      Path Patterns
      Pattern Combos
    ðŸ­ Pipeline
      Projects
      Layers
      Full Paths
```

## Data Flow

```mermaid
flowchart TB
    subgraph Sources["ðŸ“¥ Data Sources"]
        V["ðŸ¢ Vendors"]
        S["ðŸ“¡ Services"]
    end

    subgraph Pipeline["ðŸ­ Pipeline Layers"]
        RAW["ðŸ“ Raw"]
        BRONZE["ðŸ“¦ Bronze"]
        SILVER["ðŸ’Ž Silver"]
        GOLD["â­ Gold"]
        DELTA["ðŸ“ Delta"]

        RAW --> BRONZE --> SILVER --> GOLD --> DELTA
    end

    subgraph Patterns["ðŸ§© Pattern Registry"]
        FP["ðŸ“„ File Patterns"]
        PP["ðŸ“‚ Path Patterns"]
        PC["ðŸ”— Pattern Combos"]
    end

    V --> RAW
    S --> RAW
    BRONZE -.-> FP
    SILVER -.-> FP
    GOLD -.-> FP
    FP --> PC
    PP --> PC
```

## Reverse Lookup Flow

```mermaid
flowchart TD
    INPUT[/"â­ Gold: sp_global_mi/gics_direct/1.0/raw/*/*.zip"/]

    subgraph Step1["1ï¸âƒ£ Match Pattern"]
        MATCH["Find matching gold pattern"]
    end

    subgraph Step2["2ï¸âƒ£ Walk Chain"]
        CHAIN["Trace back through layers"]
    end

    subgraph Step3["3ï¸âƒ£ Get Details"]
        DETAILS["Fetch service & server info"]
    end

    subgraph Result["âœ… Result"]
        R1["ðŸ“¦ Bronze Pattern"]
        R2["âš™ï¸ Service Name"]
        R3["ðŸ–¥ï¸ Server"]
    end

    INPUT --> Step1
    Step1 --> Step2
    Step2 --> Step3
    Step3 --> R1 & R2 & R3
```

## Entity Relationships

```mermaid
erDiagram
    VENDOR ||--o{ DATASET : owns
    SERVICE ||--o{ DATASET : delivers
    SERVER ||--o{ SERVICE : hosts
    DATASET ||--o{ PATTERN_COMBO : uses
    PATTERN_COMBO ||--|{ FILE_PATTERN : contains
    PATTERN_COMBO ||--|{ PATH_PATTERN : contains
    LAYER ||--o{ FULL_PATH : defines
    FULL_PATH }o--|| PATTERN_COMBO : references
```

## Table Details

### ðŸ–¥ï¸ Infrastructure Tables

#### alchemy_server
> Production servers running Alchemy pipelines

| Column | Type | Description |
|--------|------|-------------|
| server_id | PK | Primary key |
| server_name | VARCHAR | Server hostname |
| ip_address | VARCHAR | IP address |
| cpu_cores | INT | CPU cores |
| ram_gb | INT | RAM in GB |
| disk_gb | INT | Disk in GB |
| os_version | VARCHAR | OS version |
| environment | VARCHAR | PROD/DEV |
| datacenter | VARCHAR | Datacenter location |
| status | VARCHAR | ACTIVE/INACTIVE |

```mermaid
flowchart LR
    S["ðŸ–¥ï¸ alchemy_server"] -->|hosts| SVC["âš™ï¸ alchemy_service"]
```

---

#### alchemy_service
> Systemd services running data-alchemy pipelines

| Column | Type | Description |
|--------|------|-------------|
| service_id | PK | Primary key |
| server_id | FK | â†’ alchemy_server |
| raw_id | FK | â†’ alchemy_raw |
| vendor_id | FK | â†’ vendor |
| dataset_name | VARCHAR | Dataset name |
| dataset_version | VARCHAR | Version |
| service_name | VARCHAR | Systemd service name |
| environment | VARCHAR | PROD/DEV |
| exec_script | VARCHAR | Execution script |
| watch_interval | INT | Watch interval (sec) |
| fp_prefix | VARCHAR | File path prefix |
| raw_fp_prefix | VARCHAR | Raw file path prefix |
| log_path | VARCHAR | Log file path |
| playbook_file | VARCHAR | Ansible playbook |
| is_active | BOOL | Active flag |

```mermaid
flowchart LR
    SVC["âš™ï¸ alchemy_service"] -->|on| S["ðŸ–¥ï¸ server"]
    SVC -->|processes| R["ðŸ“ raw"]
    SVC -->|for| V["ðŸ¢ vendor"]
```

---

#### vendor
> Data vendors (bloomberg, factset, sp, etc.)

| Column | Type | Description |
|--------|------|-------------|
| vendor_id | PK | Primary key |
| vendor_code | VARCHAR | Short code (sp, bb) |
| vendor_name | VARCHAR | Full name |
| website | VARCHAR | Vendor website |

```mermaid
flowchart LR
    V["ðŸ¢ vendor"] -->|owns| C["ðŸ”‘ credential"]
    V -->|provides| D["ðŸ“¡ dataset"]
```

---

#### vendor_credential
> Vendor credentials stored in AWS Secrets Manager

| Column | Type | Description |
|--------|------|-------------|
| credential_id | PK | Primary key |
| vendor_id | FK | â†’ vendor |
| aws_secret_path | VARCHAR | AWS secret path |
| credential_type | VARCHAR | sftp/api/s3 |

---

### ðŸ“¥ Data Source Tables

#### cwiq_pipe_source_dataset
> CWIQ pipe source datasets configuration

| Column | Type | Description |
|--------|------|-------------|
| source_id | PK | Primary key |
| vendor_id | FK | â†’ vendor |
| credential_id | FK | â†’ vendor_credential |
| dataset_name | VARCHAR | Dataset name |
| dataset_version | VARCHAR | Version |
| connector_type | VARCHAR | sftp/s3/api |
| exporter_type | VARCHAR | file_system |
| source_path | VARCHAR | Source path |
| source_host | VARCHAR | Source host |
| scan_time | INT | Scan interval |
| env_enabled | BOOL | Environment enabled |
| online | BOOL | Online flag |

```mermaid
flowchart LR
    V["ðŸ¢ vendor"] -->|has| DS["ðŸ“¡ cwiq_pipe_source"]
    DS -->|lands in| R["ðŸ“ alchemy_raw"]
```

---

#### alchemy_raw
> Dataset-level raw configuration

| Column | Type | Description |
|--------|------|-------------|
| raw_id | PK | Primary key |
| source_id | FK | â†’ cwiq_pipe_source_dataset |
| base_path | VARCHAR | Base landing path |
| is_live | BOOL | Live data flag |

```mermaid
flowchart LR
    R["ðŸ“ alchemy_raw"] -->|has| RFT["ðŸ”— raw_filetype"]
    R -->|uses| PC["ðŸ§© pattern_combo"]
```

---

#### filetype
> Reusable file extensions

| Column | Type | Description |
|--------|------|-------------|
| filetype_id | PK | Primary key |
| extension | VARCHAR | csv, parquet, gz |
| mime_type | VARCHAR | MIME type |
| category | VARCHAR | archive/data/text |

---

#### raw_filetype
> Links alchemy_raw to filetype (bridge)

| Column | Type | Description |
|--------|------|-------------|
| raw_filetype_id | PK | Primary key |
| raw_id | FK | â†’ alchemy_raw |
| filetype_id | FK | â†’ filetype |
| is_primary | BOOL | Primary type flag |

---

### ðŸ§© Pattern Tables

#### date_format
> Normalized date format patterns

| Column | Type | Description |
|--------|------|-------------|
| format_id | PK | Primary key |
| format_code | VARCHAR | YYYY, YYYYMMDD |
| format_regex | VARCHAR | `\d{4}`, `\d{8}` |
| example | VARCHAR | 2025, 20251210 |

---

#### file_pattern
> File name regex patterns (reusable)

| Column | Type | Description |
|--------|------|-------------|
| file_pattern_id | PK | Primary key |
| pattern_regex | VARCHAR | File regex |
| format_id | FK | â†’ date_format |

```mermaid
flowchart LR
    DF["ðŸ“… date_format"] -->|used by| FP["ðŸ“„ file_pattern"]
    FP -->|combines into| PC["ðŸ”— pattern_combo"]
```

---

#### path_pattern
> Directory path structure patterns (reusable)

| Column | Type | Description |
|--------|------|-------------|
| path_pattern_id | PK | Primary key |
| pattern_structure | VARCHAR | YYYY/MM/DD/ |
| format_id | FK | â†’ date_format |

```mermaid
flowchart LR
    DF["ðŸ“… date_format"] -->|used by| PP["ðŸ“‚ path_pattern"]
    PP -->|combines into| PC["ðŸ”— pattern_combo"]
```

---

#### pattern_combo
> Combines file_pattern + path_pattern (reusable)

| Column | Type | Description |
|--------|------|-------------|
| combo_id | PK | Primary key |
| file_pattern_id | FK | â†’ file_pattern |
| path_pattern_id | FK | â†’ path_pattern |
| description | VARCHAR | Combo description |

```mermaid
flowchart TB
    FP["ðŸ“„ file_pattern"] --> PC["ðŸ”— pattern_combo"]
    PP["ðŸ“‚ path_pattern"] --> PC
    PC --> EX["ðŸ‘ï¸ path_example"]
    PC --> FPP["ðŸ—ºï¸ full_path_pattern"]
```

---

#### path_example
> Full path examples linked to pattern_combo

| Column | Type | Description |
|--------|------|-------------|
| example_id | PK | Primary key |
| combo_id | FK | â†’ pattern_combo |
| example_filename | VARCHAR | Full filename |
| example_rel_path | VARCHAR | Relative path |
| file_date | DATE | File date |

---

#### raw_pattern_rel
> Links alchemy_raw to pattern_combo (bridge)

| Column | Type | Description |
|--------|------|-------------|
| rel_id | PK | Primary key |
| raw_id | FK | â†’ alchemy_raw |
| combo_id | FK | â†’ pattern_combo |
| is_active | BOOL | Active flag |

---

### ðŸ­ Pipeline Tables

#### project
> Systems that generate/manage data layers

| Column | Type | Description |
|--------|------|-------------|
| project_id | PK | Primary key |
| project_name | VARCHAR | cwiq_pipe, data_alchemy, cds_job |
| repo_url | VARCHAR | Git repo URL |

---

#### layer
> Data pipeline layers

| Column | Type | Description |
|--------|------|-------------|
| layer_id | PK | Primary key |
| layer_name | VARCHAR | raw, bronze, silver, gold |
| project_id | FK | â†’ project |
| layer_order | INT | Layer sequence |

```mermaid
flowchart LR
    P["ðŸ’¼ project"] -->|has| L["ðŸ—‚ï¸ layer"]
    L -->|defines| FPP["ðŸ—ºï¸ full_path_pattern"]
```

---

#### full_path_pattern
> Complete paths for traceability and impact analysis

| Column | Type | Description |
|--------|------|-------------|
| full_path_id | PK | Primary key |
| combo_id | FK | â†’ pattern_combo |
| layer_id | FK | â†’ layer |
| base_path | VARCHAR | Base path |
| full_path_pattern | VARCHAR | Full pattern |
| full_path_example | VARCHAR | Example path |
| is_active | BOOL | Active flag |

---

### ðŸ“ CDP Retirement Tables

#### delta_dataset_repo
> Unique dataset repository names

| Column | Type | Description |
|--------|------|-------------|
| repo_id | PK | Primary key |
| repo_name | VARCHAR | Repository name |

---

#### delta_table
> SF table names with repo relationship

| Column | Type | Description |
|--------|------|-------------|
| table_id | PK | Primary key |
| sf_table_name | VARCHAR | Snowflake table name |
| repo_id | FK | â†’ delta_dataset_repo |

```mermaid
flowchart LR
    R["ðŸ“¦ delta_dataset_repo"] -->|contains| T["ðŸ“ delta_table"]
    T -->|mapped in| D["â­ raw_enriched_data"]
```

---

#### raw_enriched_directory
> Unique enriched directory paths

| Column | Type | Description |
|--------|------|-------------|
| directory_id | PK | Primary key |
| directory_path | VARCHAR | Directory path |

---

#### raw_enriched_file_pattern
> File patterns with regex and examples

| Column | Type | Description |
|--------|------|-------------|
| pattern_id | PK | Primary key |
| file_pattern | VARCHAR | File pattern |
| file_regex | VARCHAR | Regex version |
| file_example | VARCHAR | Example filename |

---

#### raw_enriched_data
> Maps tables to directories and patterns (fact)

| Column | Type | Description |
|--------|------|-------------|
| enriched_id | PK | Primary key |
| table_id | FK | â†’ delta_table |
| directory_id | FK | â†’ raw_enriched_directory |
| pattern_id | FK | â†’ raw_enriched_file_pattern |

```mermaid
flowchart TB
    T["ðŸ“ delta_table"] --> D["â­ raw_enriched_data"]
    DIR["ðŸ“‚ directory"] --> D
    P["ðŸ“„ file_pattern"] --> D
```

## Layers

```mermaid
flowchart LR
    subgraph Layers
        direction TB
        L1["1ï¸âƒ£ raw"]
        L2["2ï¸âƒ£ bronze"]
        L3["3ï¸âƒ£ silver"]
        L4["4ï¸âƒ£ gold"]
        L5["5ï¸âƒ£ raw_enriched"]
        L6["6ï¸âƒ£ delta"]
    end

    L1 --> L2 --> L3 --> L4 --> L5 --> L6
```

| Layer | Description |
|-------|-------------|
| ðŸ“¥ raw | Landing zone (cwiq-pipe) |
| ðŸ“¦ bronze | Timestamped archives |
| ðŸ’Ž silver | Extracted files |
| â­ gold | Restructured/renamed |
| ðŸ—„ï¸ raw_enriched | CDP legacy format |
| ðŸ“ delta | Delta Lake tables |

## Use Cases

```mermaid
flowchart TB
    subgraph UC["Use Cases"]
        UC1["ðŸ” Reverse Lookup"]
        UC2["âš ï¸ Impact Analysis"]
        UC3["âš™ï¸ Service Discovery"]
        UC4["ðŸ‘£ Pattern Tracing"]
    end

    UC1 --> |"Gold â†’ Bronze"| R1["Find source pattern"]
    UC2 --> |"Missing file"| R2["Find affected datasets"]
    UC3 --> |"Vendor + Dataset"| R3["Find server & service"]
    UC4 --> |"combo_id"| R4["Trace across all layers"]
```

## Pattern Types

```mermaid
flowchart LR
    subgraph FilePatterns["ðŸ“„ File Patterns"]
        FP1["HHMMSS--*.tar.gz"]
        FP2["*.parquet"]
        FP3["*.csv"]
    end

    subgraph PathPatterns["ðŸ“‚ Path Patterns"]
        PP1["YYYY/MM/DD/"]
        PP2["YYYY/YYYYMMDD/"]
        PP3["YYYY/"]
    end

    subgraph Combo["ðŸ”— Pattern Combo"]
        C["File + Path = Full Pattern"]
    end

    FilePatterns --> Combo
    PathPatterns --> Combo
```

## CLI Ideas

```mermaid
flowchart LR
    subgraph Commands
        C1["invdb reverse"]
        C2["invdb service"]
        C3["invdb servers"]
        C4["invdb trace"]
        C5["invdb impact"]
    end

    C1 --> |"--gold pattern"| O1["ðŸ“¦ Bronze + Service"]
    C2 --> |"--vendor --dataset"| O2["ðŸ–¥ï¸ Server info"]
    C3 --> |"--list"| O3["All servers"]
    C4 --> |"--combo-id"| O4["Full path chain"]
    C5 --> |"--layer --pattern"| O5["Affected datasets"]
```

## Integration

```mermaid
flowchart LR
    subgraph Tools
        PS["ðŸ” PathSeeker"]
        DB["ðŸ—„ï¸ Investigation DB"]
        DS["ðŸ“Š Datasette"]
    end

    PS --> |"extract patterns"| DB
    DB --> |"browse & query"| DS
```

## References

- ðŸ”— **Repo:** [alchmydb](https://git.codewilling.com/alchmy/database/alchmydb)
- ðŸ”— **Related:** [PathSeeker](pathseeker.md)
